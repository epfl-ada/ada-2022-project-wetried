{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a2b9ca-f5b8-4458-baba-a0add2e919e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Coronawiki dataset exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173e86f-d8e0-4cb1-ada3-cb2e953d9dc9",
   "metadata": {},
   "source": [
    "The purpose of the following notebook is to get familiar with the given Coronawiki data, as it is split among multiple files which serve different purposes.\n",
    "\n",
    "As such, we will attempt to do the following tasks in this notebook:\n",
    "\n",
    "- Preprocessing of the data,to make it more comfortable to use (Split the dataframes, give them another format, etc)\n",
    "- Data wrangling: a lot of the data are timeseries which could be put together to derive interesting results\n",
    "- First analysis phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38023639-fe84-4988-b2ec-e1f66a56447f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51c2e7a-4e8c-4f27-ab6b-c2ab12b84fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import pycountry_convert as pc\n",
    "import os\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78d225-07e1-4f7f-8890-6282358da950",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Timeseries <a id='timeseries'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9765f8-23a8-47b4-9130-a831b40779dc",
   "metadata": {},
   "source": [
    "The most important data we have in this dataset are time series of the Wikipedia views from 2018 to July 2020 for 14 different languages: one part are the total views for all of that language's wikipedia, a second part are the views for the articles that are related to Covid-19, as well as the percentage. Finally, we also have for the same window of time the views for different topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deeaf6e7-2a8c-428b-a678-12914bb73472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ja.m</th>\n",
       "      <th>it</th>\n",
       "      <th>da.m</th>\n",
       "      <th>tr</th>\n",
       "      <th>no.m</th>\n",
       "      <th>en</th>\n",
       "      <th>sr</th>\n",
       "      <th>tr.m</th>\n",
       "      <th>en.m</th>\n",
       "      <th>no</th>\n",
       "      <th>...</th>\n",
       "      <th>ko.m</th>\n",
       "      <th>fi.m</th>\n",
       "      <th>sr.m</th>\n",
       "      <th>ja</th>\n",
       "      <th>fr</th>\n",
       "      <th>fi</th>\n",
       "      <th>ca</th>\n",
       "      <th>it.m</th>\n",
       "      <th>sv.m</th>\n",
       "      <th>ko</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>1197788</td>\n",
       "      <td>1594039</td>\n",
       "      <td>256451</td>\n",
       "      <td>346007</td>\n",
       "      <td>516838</td>\n",
       "      <td>6047509</td>\n",
       "      <td>632128</td>\n",
       "      <td>345790</td>\n",
       "      <td>6045654</td>\n",
       "      <td>531478</td>\n",
       "      <td>...</td>\n",
       "      <td>489181</td>\n",
       "      <td>480638</td>\n",
       "      <td>396063</td>\n",
       "      <td>1197856</td>\n",
       "      <td>2195949</td>\n",
       "      <td>481854</td>\n",
       "      <td>642031</td>\n",
       "      <td>1588312</td>\n",
       "      <td>1959446</td>\n",
       "      <td>490314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>{'2018-01-01 00:00:00': 22328288, '2018-01-02 ...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 3338750, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 765123, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 407629, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 715031, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 86763830, '2018-01-02 ...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 192409, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 493684, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 135822131, '2018-01-02...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 224417, '2018-01-02 00...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 1484496, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 1319053, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 451383, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 7828155, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 6441009, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 523135, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 111910, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 12856884, '2018-01-02 ...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 2383474, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 819174, '2018-01-02 00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>{'len': 30, 'sum': {'2018-01-01 00:00:00': 55,...</td>\n",
       "      <td>{'len': 33, 'sum': {'2018-01-01 00:00:00': 50,...</td>\n",
       "      <td>{'len': 4, 'sum': {'2018-01-01 00:00:00': 0, '...</td>\n",
       "      <td>{'len': 64, 'sum': {'2018-01-01 00:00:00': 1, ...</td>\n",
       "      <td>{'len': 10, 'sum': {'2018-01-01 00:00:00': 7, ...</td>\n",
       "      <td>{'len': 306, 'sum': {'2018-01-01 00:00:00': 57...</td>\n",
       "      <td>{'len': 9, 'sum': {'2018-01-01 00:00:00': 6, '...</td>\n",
       "      <td>{'len': 64, 'sum': {'2018-01-01 00:00:00': 3, ...</td>\n",
       "      <td>{'len': 306, 'sum': {'2018-01-01 00:00:00': 91...</td>\n",
       "      <td>{'len': 10, 'sum': {'2018-01-01 00:00:00': 2, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'len': 113, 'sum': {'2018-01-01 00:00:00': 6,...</td>\n",
       "      <td>{'len': 9, 'sum': {'2018-01-01 00:00:00': 0, '...</td>\n",
       "      <td>{'len': 9, 'sum': {'2018-01-01 00:00:00': 11, ...</td>\n",
       "      <td>{'len': 30, 'sum': {'2018-01-01 00:00:00': 26,...</td>\n",
       "      <td>{'len': 16, 'sum': {'2018-01-01 00:00:00': 62,...</td>\n",
       "      <td>{'len': 9, 'sum': {'2018-01-01 00:00:00': 2, '...</td>\n",
       "      <td>{'len': 49, 'sum': {'2018-01-01 00:00:00': 6, ...</td>\n",
       "      <td>{'len': 33, 'sum': {'2018-01-01 00:00:00': 139...</td>\n",
       "      <td>{'len': 8, 'sum': {'2018-01-01 00:00:00': 19, ...</td>\n",
       "      <td>{'len': 113, 'sum': {'2018-01-01 00:00:00': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topics</th>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 14904...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 29427...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 57720...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 70443...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 11603...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 14038...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 37718...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 70434...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 14038...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 11804...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 75406...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 10422...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 37580...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 14904...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 38258...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 10444...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 10175...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 29422...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 14668...</td>\n",
       "      <td>{'Culture.Biography.Biography*': {'len': 75498...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     ja.m  \\\n",
       "len                                               1197788   \n",
       "sum     {'2018-01-01 00:00:00': 22328288, '2018-01-02 ...   \n",
       "covid   {'len': 30, 'sum': {'2018-01-01 00:00:00': 55,...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 14904...   \n",
       "\n",
       "                                                       it  \\\n",
       "len                                               1594039   \n",
       "sum     {'2018-01-01 00:00:00': 3338750, '2018-01-02 0...   \n",
       "covid   {'len': 33, 'sum': {'2018-01-01 00:00:00': 50,...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 29427...   \n",
       "\n",
       "                                                     da.m  \\\n",
       "len                                                256451   \n",
       "sum     {'2018-01-01 00:00:00': 765123, '2018-01-02 00...   \n",
       "covid   {'len': 4, 'sum': {'2018-01-01 00:00:00': 0, '...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 57720...   \n",
       "\n",
       "                                                       tr  \\\n",
       "len                                                346007   \n",
       "sum     {'2018-01-01 00:00:00': 407629, '2018-01-02 00...   \n",
       "covid   {'len': 64, 'sum': {'2018-01-01 00:00:00': 1, ...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 70443...   \n",
       "\n",
       "                                                     no.m  \\\n",
       "len                                                516838   \n",
       "sum     {'2018-01-01 00:00:00': 715031, '2018-01-02 00...   \n",
       "covid   {'len': 10, 'sum': {'2018-01-01 00:00:00': 7, ...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 11603...   \n",
       "\n",
       "                                                       en  \\\n",
       "len                                               6047509   \n",
       "sum     {'2018-01-01 00:00:00': 86763830, '2018-01-02 ...   \n",
       "covid   {'len': 306, 'sum': {'2018-01-01 00:00:00': 57...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 14038...   \n",
       "\n",
       "                                                       sr  \\\n",
       "len                                                632128   \n",
       "sum     {'2018-01-01 00:00:00': 192409, '2018-01-02 00...   \n",
       "covid   {'len': 9, 'sum': {'2018-01-01 00:00:00': 6, '...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 37718...   \n",
       "\n",
       "                                                     tr.m  \\\n",
       "len                                                345790   \n",
       "sum     {'2018-01-01 00:00:00': 493684, '2018-01-02 00...   \n",
       "covid   {'len': 64, 'sum': {'2018-01-01 00:00:00': 3, ...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 70434...   \n",
       "\n",
       "                                                     en.m  \\\n",
       "len                                               6045654   \n",
       "sum     {'2018-01-01 00:00:00': 135822131, '2018-01-02...   \n",
       "covid   {'len': 306, 'sum': {'2018-01-01 00:00:00': 91...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 14038...   \n",
       "\n",
       "                                                       no  ...  \\\n",
       "len                                                531478  ...   \n",
       "sum     {'2018-01-01 00:00:00': 224417, '2018-01-02 00...  ...   \n",
       "covid   {'len': 10, 'sum': {'2018-01-01 00:00:00': 2, ...  ...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 11804...  ...   \n",
       "\n",
       "                                                     ko.m  \\\n",
       "len                                                489181   \n",
       "sum     {'2018-01-01 00:00:00': 1484496, '2018-01-02 0...   \n",
       "covid   {'len': 113, 'sum': {'2018-01-01 00:00:00': 6,...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 75406...   \n",
       "\n",
       "                                                     fi.m  \\\n",
       "len                                                480638   \n",
       "sum     {'2018-01-01 00:00:00': 1319053, '2018-01-02 0...   \n",
       "covid   {'len': 9, 'sum': {'2018-01-01 00:00:00': 0, '...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 10422...   \n",
       "\n",
       "                                                     sr.m  \\\n",
       "len                                                396063   \n",
       "sum     {'2018-01-01 00:00:00': 451383, '2018-01-02 00...   \n",
       "covid   {'len': 9, 'sum': {'2018-01-01 00:00:00': 11, ...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 37580...   \n",
       "\n",
       "                                                       ja  \\\n",
       "len                                               1197856   \n",
       "sum     {'2018-01-01 00:00:00': 7828155, '2018-01-02 0...   \n",
       "covid   {'len': 30, 'sum': {'2018-01-01 00:00:00': 26,...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 14904...   \n",
       "\n",
       "                                                       fr  \\\n",
       "len                                               2195949   \n",
       "sum     {'2018-01-01 00:00:00': 6441009, '2018-01-02 0...   \n",
       "covid   {'len': 16, 'sum': {'2018-01-01 00:00:00': 62,...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 38258...   \n",
       "\n",
       "                                                       fi  \\\n",
       "len                                                481854   \n",
       "sum     {'2018-01-01 00:00:00': 523135, '2018-01-02 00...   \n",
       "covid   {'len': 9, 'sum': {'2018-01-01 00:00:00': 2, '...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 10444...   \n",
       "\n",
       "                                                       ca  \\\n",
       "len                                                642031   \n",
       "sum     {'2018-01-01 00:00:00': 111910, '2018-01-02 00...   \n",
       "covid   {'len': 49, 'sum': {'2018-01-01 00:00:00': 6, ...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 10175...   \n",
       "\n",
       "                                                     it.m  \\\n",
       "len                                               1588312   \n",
       "sum     {'2018-01-01 00:00:00': 12856884, '2018-01-02 ...   \n",
       "covid   {'len': 33, 'sum': {'2018-01-01 00:00:00': 139...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 29422...   \n",
       "\n",
       "                                                     sv.m  \\\n",
       "len                                               1959446   \n",
       "sum     {'2018-01-01 00:00:00': 2383474, '2018-01-02 0...   \n",
       "covid   {'len': 8, 'sum': {'2018-01-01 00:00:00': 19, ...   \n",
       "topics  {'Culture.Biography.Biography*': {'len': 14668...   \n",
       "\n",
       "                                                       ko  \n",
       "len                                                490314  \n",
       "sum     {'2018-01-01 00:00:00': 819174, '2018-01-02 00...  \n",
       "covid   {'len': 113, 'sum': {'2018-01-01 00:00:00': 3,...  \n",
       "topics  {'Culture.Biography.Biography*': {'len': 75498...  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries = pd.read_json(\"aggregated_timeseries.json.gz\")\n",
    "timeseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b649c408-ed5b-4c8e-ac9c-5bea8dc8a453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ja.m', 'it', 'da.m', 'tr', 'no.m', 'en', 'sr', 'tr.m', 'en.m', 'no',\n",
       "       'sv', 'nl.m', 'nl', 'da', 'de', 'fr.m', 'ca.m', 'de.m', 'ko.m', 'fi.m',\n",
       "       'sr.m', 'ja', 'fr', 'fi', 'ca', 'it.m', 'sv.m', 'ko'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38bf7c9a-e909-4a61-90ef-6b2a8bf74668",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_unique = timeseries.columns.map(lambda x: x[:2]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fad198-ccc3-4c53-b441-8acc7399b9eb",
   "metadata": {},
   "source": [
    "Correspondence:\n",
    "- ja -> Japanese\n",
    "- it -> Italian\n",
    "- da -> Danish\n",
    "- tr -> Turkish?\n",
    "- no -> Norwegian\n",
    "- en -> English\n",
    "- sr -> Serbian\n",
    "- sv -> Swedish\n",
    "- nl -> Dutch\n",
    "- de -> German\n",
    "- fr -> French\n",
    "- ca -> Catalan?\n",
    "- ko -> Korean\n",
    "- fi -> Finnish\n",
    "\n",
    "Not sure about the \"?\" ones. According to https://www.loc.gov/standards/iso639-2/php/langcodes-search.php, these correspond respectively to Turkish and Catalan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af0543-42ba-4fac-84f5-bd6fb9fcd043",
   "metadata": {},
   "source": [
    "### Splitting the timeseries data into different dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956be76d-7cae-4512-8a32-c7cf272f31d2",
   "metadata": {},
   "source": [
    "As we can see, the data's format isn't ideal: for each language, the data is split into 3 Python dictionaries corresponding to the data described above, and it would be nice to separate these pieces of data to be able to read directly for each date, for example, the total number of views accross all languages, instead of having to iterate over each language's dictionnary every time.\n",
    "\n",
    "This will also make the analysis phase easier later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958e114-0524-4cc0-a7d7-6c773a367460",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Total sum of views, views of articles related to Covid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148dee0-e4c9-4baf-a551-f7279f58af8a",
   "metadata": {},
   "source": [
    "<a id='extraction_format'></a>\n",
    "In this part of the code we extract two following kind of data (there are three total dataframes, but the two last ones represent the same data), for each date:\n",
    "- For every language's Wikipedia, the total number of views on that particular date\n",
    "- For every language's Wikipedia, the total number of views for articles related to Covid-19 on that particular date\n",
    "- For every language's Wikipedia, the percentage of views for articles related to Covid-19 on that particular date\n",
    "\n",
    "Note that the two last dataframes might be redundant, but as we're given the data anyway, we choose to extract it after all.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Every resulting dataframe will have the following format:\n",
    "\n",
    " Column name          | Description                                                                                                                                                                                       |   |   |   |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|---|---|\n",
    "| date           | A particular date between January 2018 (inclusive) and July of 2020 (inclusive)                                                                                                                                             |   |   |   |\n",
    "| language       | The corresponding wikipedia language                                                                |  \n",
    " |   |   |\n",
    "| views  | The number of views (total or only for articles related to Covid-19) for this language and date\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "We also extract another dataframe that simply maps for each language the number of articles that were considered in the original experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747d801b-035b-47b2-ae3a-b71720b08bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeseries_total_sum_dict = {}\n",
    "timeseries_covid_len_dict = {}\n",
    "timeseries_covid_sum_dict = {}\n",
    "timeseries_covid_percent_dict = {}\n",
    "for cn in timeseries.columns:\n",
    "    timeseries_total_sum_dict[cn] = timeseries[cn]['sum']\n",
    "    timeseries_covid_len_dict[cn] = timeseries[cn]['covid']['len']\n",
    "    timeseries_covid_sum_dict[cn] = timeseries[cn]['covid']['sum']\n",
    "    timeseries_covid_percent_dict[cn] = timeseries[cn]['covid']['percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39aad657-d85a-4535-8234-2632d7a97eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_data_df = pd.DataFrame.from_dict(timeseries_total_sum_dict, orient = 'index').T\n",
    "covid_len_data_df = pd.DataFrame.from_dict(timeseries_covid_len_dict, orient = 'index', columns = ['len']).T\n",
    "covid_sum_data_df = pd.DataFrame.from_dict(timeseries_covid_sum_dict, orient = 'index').T\n",
    "covid_percent_data_df = pd.DataFrame.from_dict(timeseries_covid_percent_dict, orient = 'index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8caf01f5-40d9-4c1a-bfac-3a689a02ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse the .m and the normal columns together, and separate the data\n",
    "new_sum_data_df = pd.DataFrame()\n",
    "new_covid_sum_data_df = pd.DataFrame()\n",
    "for language in languages_unique:\n",
    "    country_sum_data = pd.DataFrame()\n",
    "    country_sum_data['views'] = sum_data_df[language] + sum_data_df[language + '.m']\n",
    "    country_sum_data['language'] = language\n",
    "    new_sum_data_df = pd.concat([new_sum_data_df, country_sum_data], axis = 0)\n",
    "    \n",
    "    country_covid_sum_data = pd.DataFrame()\n",
    "    country_covid_sum_data['views'] = covid_sum_data_df[language] + covid_sum_data_df[language + '.m']\n",
    "    country_covid_sum_data['language'] = language\n",
    "    new_covid_sum_data_df = pd.concat([new_covid_sum_data_df, country_covid_sum_data], axis = 0)\n",
    "    \n",
    "sum_data_df = new_sum_data_df\n",
    "covid_sum_data_df = new_covid_sum_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15db6b2-b314-48f1-911b-cf1313d47d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>30156443</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:00:00</th>\n",
       "      <td>31038338</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03 00:00:00</th>\n",
       "      <td>33628914</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04 00:00:00</th>\n",
       "      <td>33870576</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 00:00:00</th>\n",
       "      <td>33481670</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        views language\n",
       "2018-01-01 00:00:00  30156443       ja\n",
       "2018-01-02 00:00:00  31038338       ja\n",
       "2018-01-03 00:00:00  33628914       ja\n",
       "2018-01-04 00:00:00  33870576       ja\n",
       "2018-01-05 00:00:00  33481670       ja"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2747f2cf-65a7-48a8-957f-1bebdd8408a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_data_df.index = covid_sum_data_df.index =  pd.to_datetime(sum_data_df.index)\n",
    "covid_percent_data_df.index = pd.to_datetime(covid_percent_data_df.index)\n",
    "sum_data_df['date'] = covid_sum_data_df['date'] = sum_data_df.index\n",
    "covid_percent_data_df['date'] = covid_percent_data_df.index\n",
    "#covid_sum_data_df = covid_sum_data_df[new_column_order]\n",
    "#covid_percent_data_df = covid_percent_data_df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "404ef611-f25f-4d80-b02f-207d6eacc0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>30156443</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>31038338</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>33628914</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>33870576</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>33481670</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               views language       date\n",
       "2018-01-01  30156443       ja 2018-01-01\n",
       "2018-01-02  31038338       ja 2018-01-02\n",
       "2018-01-03  33628914       ja 2018-01-03\n",
       "2018-01-04  33870576       ja 2018-01-04\n",
       "2018-01-05  33481670       ja 2018-01-05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb97cca4-5916-42c4-8068-08d0f69236c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>81</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>97</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>104</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>160</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>204</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            views language       date\n",
       "2018-01-01     81       ja 2018-01-01\n",
       "2018-01-02     97       ja 2018-01-02\n",
       "2018-01-03    104       ja 2018-01-03\n",
       "2018-01-04    160       ja 2018-01-04\n",
       "2018-01-05    204       ja 2018-01-05"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_sum_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f3e7f79-4ad2-4521-81d6-7ed03b827f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ja.m</th>\n",
       "      <th>it</th>\n",
       "      <th>da.m</th>\n",
       "      <th>tr</th>\n",
       "      <th>no.m</th>\n",
       "      <th>en</th>\n",
       "      <th>sr</th>\n",
       "      <th>tr.m</th>\n",
       "      <th>en.m</th>\n",
       "      <th>no</th>\n",
       "      <th>...</th>\n",
       "      <th>fi.m</th>\n",
       "      <th>sr.m</th>\n",
       "      <th>ja</th>\n",
       "      <th>fr</th>\n",
       "      <th>fi</th>\n",
       "      <th>ca</th>\n",
       "      <th>it.m</th>\n",
       "      <th>sv.m</th>\n",
       "      <th>ko</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ja.m        it      da.m        tr      no.m        en  \\\n",
       "2018-01-01  0.000002  0.000015  0.000000  0.000002  0.000010  0.000007   \n",
       "2018-01-02  0.000002  0.000019  0.000005  0.000007  0.000009  0.000010   \n",
       "2018-01-03  0.000002  0.000023  0.000002  0.000013  0.000004  0.000010   \n",
       "2018-01-04  0.000002  0.000019  0.000000  0.000002  0.000004  0.000010   \n",
       "2018-01-05  0.000003  0.000022  0.000000  0.000000  0.000003  0.000010   \n",
       "\n",
       "                  sr      tr.m      en.m        no  ...      fi.m      sr.m  \\\n",
       "2018-01-01  0.000031  0.000006  0.000007  0.000009  ...  0.000000  0.000024   \n",
       "2018-01-02  0.000051  0.000004  0.000008  0.000011  ...  0.000000  0.000043   \n",
       "2018-01-03  0.000040  0.000004  0.000008  0.000007  ...  0.000008  0.000037   \n",
       "2018-01-04  0.000022  0.000019  0.000009  0.000002  ...  0.000000  0.000077   \n",
       "2018-01-05  0.000051  0.000004  0.000008  0.000009  ...  0.000000  0.000087   \n",
       "\n",
       "                  ja        fr        fi        ca      it.m      sv.m  \\\n",
       "2018-01-01  0.000003  0.000010  0.000004  0.000054  0.000011  0.000008   \n",
       "2018-01-02  0.000005  0.000010  0.000003  0.000030  0.000015  0.000006   \n",
       "2018-01-03  0.000005  0.000011  0.000003  0.000048  0.000013  0.000007   \n",
       "2018-01-04  0.000010  0.000011  0.000005  0.000049  0.000015  0.000008   \n",
       "2018-01-05  0.000011  0.000012  0.000000  0.000024  0.000010  0.000005   \n",
       "\n",
       "                  ko       date  \n",
       "2018-01-01  0.000004 2018-01-01  \n",
       "2018-01-02  0.000021 2018-01-02  \n",
       "2018-01-03  0.000019 2018-01-03  \n",
       "2018-01-04  0.000017 2018-01-04  \n",
       "2018-01-05  0.000021 2018-01-05  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_percent_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96da1c7-30e7-46ab-9c34-1fa00e05e490",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Checking for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c6c00-548c-4fd6-b0dd-8cced69a4a3d",
   "metadata": {},
   "source": [
    "Before continuing further, let us check for missing data in the timeseries; this will help us avoid bad surprises later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb626920-6a4b-43b7-8d84-a5a7a67d1b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_data_df.isnull().any().any(), covid_sum_data_df.isnull().any().any(), covid_percent_data_df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77dfa88-b18a-4bb4-a5a9-ee4cd8fe9c5a",
   "metadata": {},
   "source": [
    "There appears to be some missing data in the percentage dataframe; let's check by language where that missing data is reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77fee81b-53e2-4f33-b721-35fd53aa1f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sv    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data_language = covid_percent_data_df.isnull().any(axis = 0)\n",
    "missing_data_language[missing_data_language]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e51a9c-20b9-435f-a955-4a63cde65053",
   "metadata": {},
   "source": [
    "Looking at the paper, this corresponds to Swedish. Let's check, in the original data, how these missing values manifest themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e1a1c80-5a50-4120-a8e9-6746b87713ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decomment Run this cell if you want to see how the missing data can be seen in the original timeseries\n",
    "#timeseries.loc[:,'sv']['sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b53f9-5051-4254-b813-b5e5265417d7",
   "metadata": {},
   "source": [
    "It appears that, for desktop devices, the views for the Swedish Wikipedia haven't been collected for the whole year 2018. The reason for that is unknown, as a quick search tells us that this version has existed since 2001. We will need to take this into account when doing our analysis in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92981e10-3ca3-40b3-88d5-e95806ad233b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Topics data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d1c4bc-775a-4219-b30e-0283a000d45f",
   "metadata": {},
   "source": [
    "Now we will extract for each language, all the views per topic in such a way that the data becomes more usable. In the original data, all topic-related information was in a single dictionnary; we're gonna separate them in a way that each column will correspond to a different topic, with each row being a different language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbe9b008-63c5-4621-a469-cd2a76d6884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_topics = {}\n",
    "for cn in timeseries.columns:\n",
    "    country_to_topics[cn] = timeseries[cn]['topics']\n",
    "topics_df = pd.DataFrame.from_dict(country_to_topics, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e67fda-61ad-45f8-bb20-e74f0932e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_to_topics_len = {}\n",
    "countries_to_topics_sum = {}\n",
    "countries_to_topics_percent = {}\n",
    "for country in topics_df.index:\n",
    "    countries_to_topics_len[country] = {}\n",
    "    countries_to_topics_sum[country] = {}\n",
    "    countries_to_topics_percent[country] = {}\n",
    "    for topic in topics_df.columns:\n",
    "        countries_to_topics_len[country][topic] = topics_df.loc[country,topic]['len']\n",
    "        countries_to_topics_sum[country][topic] = topics_df.loc[country,topic]['sum']\n",
    "        countries_to_topics_percent[country][topic] = topics_df.loc[country,topic]['percent']\n",
    "countries_to_topics_len_df = pd.DataFrame.from_dict(countries_to_topics_len, orient = 'index')\n",
    "countries_to_topics_sum_df = pd.DataFrame.from_dict(countries_to_topics_sum, orient = 'index')\n",
    "countries_to_topics_percent_df = pd.DataFrame.from_dict(countries_to_topics_percent, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eed7596-8fc1-46b0-b0b0-00810eca8bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culture.Biography.Biography*</th>\n",
       "      <th>Culture.Biography.Women</th>\n",
       "      <th>Culture.Food and drink</th>\n",
       "      <th>Culture.Internet culture</th>\n",
       "      <th>Culture.Linguistics</th>\n",
       "      <th>Culture.Literature</th>\n",
       "      <th>Culture.Media.Books</th>\n",
       "      <th>Culture.Media.Entertainment</th>\n",
       "      <th>Culture.Media.Films</th>\n",
       "      <th>Culture.Media.Media*</th>\n",
       "      <th>...</th>\n",
       "      <th>STEM.Computing</th>\n",
       "      <th>STEM.Earth and environment</th>\n",
       "      <th>STEM.Engineering</th>\n",
       "      <th>STEM.Libraries &amp; Information</th>\n",
       "      <th>STEM.Mathematics</th>\n",
       "      <th>STEM.Medicine &amp; Health</th>\n",
       "      <th>STEM.Physics</th>\n",
       "      <th>STEM.STEM*</th>\n",
       "      <th>STEM.Space</th>\n",
       "      <th>STEM.Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ja.m</th>\n",
       "      <td>{'2018-01-01 00:00:00': 6629234, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 1462146, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 302934, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 443986, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 109480, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 2140880, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 97435, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 238059, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 681533, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 4264889, '2018-01-02 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 91338, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 72493, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 316615, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 10072, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 44902, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 485801, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 76863, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 1793359, '2018-01-02 0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 64445, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 264636, '2018-01-02 00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>{'2018-01-01 00:00:00': 809879, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 193009, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 34632, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 66037, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 23304, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 206403, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 50646, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 86717, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 395631, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 1137084, '2018-01-02 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 41406, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 20273, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 51490, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 7526, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 15705, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 76109, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 31334, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 383789, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 18815, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 78432, '2018-01-02 00:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da.m</th>\n",
       "      <td>{'2018-01-01 00:00:00': 289706, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 74001, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 13610, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 4361, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 4238, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 28733, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 8817, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 13707, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 47315, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 269483, '2018-01-02 00...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 2505, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 3840, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 6923, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 226, '2018-01-02 00:00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 1783, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 12618, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 3836, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 62767, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 2775, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 7414, '2018-01-02 00:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>{'2018-01-01 00:00:00': 98424, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 14151, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 3154, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 7279, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 9300, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 14074, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 3511, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 3366, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 10859, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 54290, '2018-01-02 00:...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 7422, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 3512, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 6465, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 1297, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 2732, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 8190, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 6441, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 59353, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 4067, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 13951, '2018-01-02 00:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no.m</th>\n",
       "      <td>{'2018-01-01 00:00:00': 232404, '2018-01-02 00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 64920, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 15889, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 5802, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 7222, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 27984, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 9003, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 9807, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 27301, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 153531, '2018-01-02 00...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 2907, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 6839, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 10382, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 596, '2018-01-02 00:00...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 1871, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 21247, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 6604, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 97684, '2018-01-02 00:...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 3576, '2018-01-02 00:0...</td>\n",
       "      <td>{'2018-01-01 00:00:00': 10887, '2018-01-02 00:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Culture.Biography.Biography*  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 6629234, '2018-01-02 0...   \n",
       "it    {'2018-01-01 00:00:00': 809879, '2018-01-02 00...   \n",
       "da.m  {'2018-01-01 00:00:00': 289706, '2018-01-02 00...   \n",
       "tr    {'2018-01-01 00:00:00': 98424, '2018-01-02 00:...   \n",
       "no.m  {'2018-01-01 00:00:00': 232404, '2018-01-02 00...   \n",
       "\n",
       "                                Culture.Biography.Women  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 1462146, '2018-01-02 0...   \n",
       "it    {'2018-01-01 00:00:00': 193009, '2018-01-02 00...   \n",
       "da.m  {'2018-01-01 00:00:00': 74001, '2018-01-02 00:...   \n",
       "tr    {'2018-01-01 00:00:00': 14151, '2018-01-02 00:...   \n",
       "no.m  {'2018-01-01 00:00:00': 64920, '2018-01-02 00:...   \n",
       "\n",
       "                                 Culture.Food and drink  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 302934, '2018-01-02 00...   \n",
       "it    {'2018-01-01 00:00:00': 34632, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 13610, '2018-01-02 00:...   \n",
       "tr    {'2018-01-01 00:00:00': 3154, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 15889, '2018-01-02 00:...   \n",
       "\n",
       "                               Culture.Internet culture  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 443986, '2018-01-02 00...   \n",
       "it    {'2018-01-01 00:00:00': 66037, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 4361, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 7279, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 5802, '2018-01-02 00:0...   \n",
       "\n",
       "                                    Culture.Linguistics  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 109480, '2018-01-02 00...   \n",
       "it    {'2018-01-01 00:00:00': 23304, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 4238, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 9300, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 7222, '2018-01-02 00:0...   \n",
       "\n",
       "                                     Culture.Literature  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 2140880, '2018-01-02 0...   \n",
       "it    {'2018-01-01 00:00:00': 206403, '2018-01-02 00...   \n",
       "da.m  {'2018-01-01 00:00:00': 28733, '2018-01-02 00:...   \n",
       "tr    {'2018-01-01 00:00:00': 14074, '2018-01-02 00:...   \n",
       "no.m  {'2018-01-01 00:00:00': 27984, '2018-01-02 00:...   \n",
       "\n",
       "                                    Culture.Media.Books  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 97435, '2018-01-02 00:...   \n",
       "it    {'2018-01-01 00:00:00': 50646, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 8817, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 3511, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 9003, '2018-01-02 00:0...   \n",
       "\n",
       "                            Culture.Media.Entertainment  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 238059, '2018-01-02 00...   \n",
       "it    {'2018-01-01 00:00:00': 86717, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 13707, '2018-01-02 00:...   \n",
       "tr    {'2018-01-01 00:00:00': 3366, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 9807, '2018-01-02 00:0...   \n",
       "\n",
       "                                    Culture.Media.Films  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 681533, '2018-01-02 00...   \n",
       "it    {'2018-01-01 00:00:00': 395631, '2018-01-02 00...   \n",
       "da.m  {'2018-01-01 00:00:00': 47315, '2018-01-02 00:...   \n",
       "tr    {'2018-01-01 00:00:00': 10859, '2018-01-02 00:...   \n",
       "no.m  {'2018-01-01 00:00:00': 27301, '2018-01-02 00:...   \n",
       "\n",
       "                                   Culture.Media.Media*  ...  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 4264889, '2018-01-02 0...  ...   \n",
       "it    {'2018-01-01 00:00:00': 1137084, '2018-01-02 0...  ...   \n",
       "da.m  {'2018-01-01 00:00:00': 269483, '2018-01-02 00...  ...   \n",
       "tr    {'2018-01-01 00:00:00': 54290, '2018-01-02 00:...  ...   \n",
       "no.m  {'2018-01-01 00:00:00': 153531, '2018-01-02 00...  ...   \n",
       "\n",
       "                                         STEM.Computing  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 91338, '2018-01-02 00:...   \n",
       "it    {'2018-01-01 00:00:00': 41406, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 2505, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 7422, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 2907, '2018-01-02 00:0...   \n",
       "\n",
       "                             STEM.Earth and environment  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 72493, '2018-01-02 00:...   \n",
       "it    {'2018-01-01 00:00:00': 20273, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 3840, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 3512, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 6839, '2018-01-02 00:0...   \n",
       "\n",
       "                                       STEM.Engineering  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 316615, '2018-01-02 00...   \n",
       "it    {'2018-01-01 00:00:00': 51490, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 6923, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 6465, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 10382, '2018-01-02 00:...   \n",
       "\n",
       "                           STEM.Libraries & Information  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 10072, '2018-01-02 00:...   \n",
       "it    {'2018-01-01 00:00:00': 7526, '2018-01-02 00:0...   \n",
       "da.m  {'2018-01-01 00:00:00': 226, '2018-01-02 00:00...   \n",
       "tr    {'2018-01-01 00:00:00': 1297, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 596, '2018-01-02 00:00...   \n",
       "\n",
       "                                       STEM.Mathematics  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 44902, '2018-01-02 00:...   \n",
       "it    {'2018-01-01 00:00:00': 15705, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 1783, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 2732, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 1871, '2018-01-02 00:0...   \n",
       "\n",
       "                                 STEM.Medicine & Health  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 485801, '2018-01-02 00...   \n",
       "it    {'2018-01-01 00:00:00': 76109, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 12618, '2018-01-02 00:...   \n",
       "tr    {'2018-01-01 00:00:00': 8190, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 21247, '2018-01-02 00:...   \n",
       "\n",
       "                                           STEM.Physics  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 76863, '2018-01-02 00:...   \n",
       "it    {'2018-01-01 00:00:00': 31334, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 3836, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 6441, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 6604, '2018-01-02 00:0...   \n",
       "\n",
       "                                             STEM.STEM*  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 1793359, '2018-01-02 0...   \n",
       "it    {'2018-01-01 00:00:00': 383789, '2018-01-02 00...   \n",
       "da.m  {'2018-01-01 00:00:00': 62767, '2018-01-02 00:...   \n",
       "tr    {'2018-01-01 00:00:00': 59353, '2018-01-02 00:...   \n",
       "no.m  {'2018-01-01 00:00:00': 97684, '2018-01-02 00:...   \n",
       "\n",
       "                                             STEM.Space  \\\n",
       "ja.m  {'2018-01-01 00:00:00': 64445, '2018-01-02 00:...   \n",
       "it    {'2018-01-01 00:00:00': 18815, '2018-01-02 00:...   \n",
       "da.m  {'2018-01-01 00:00:00': 2775, '2018-01-02 00:0...   \n",
       "tr    {'2018-01-01 00:00:00': 4067, '2018-01-02 00:0...   \n",
       "no.m  {'2018-01-01 00:00:00': 3576, '2018-01-02 00:0...   \n",
       "\n",
       "                                        STEM.Technology  \n",
       "ja.m  {'2018-01-01 00:00:00': 264636, '2018-01-02 00...  \n",
       "it    {'2018-01-01 00:00:00': 78432, '2018-01-02 00:...  \n",
       "da.m  {'2018-01-01 00:00:00': 7414, '2018-01-02 00:0...  \n",
       "tr    {'2018-01-01 00:00:00': 13951, '2018-01-02 00:...  \n",
       "no.m  {'2018-01-01 00:00:00': 10887, '2018-01-02 00:...  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_to_topics_sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82d65c77-71cf-4370-b385-b2b415d6ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomment and run this cell to see all available topics.\n",
    "#countries_to_topics_sum_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d88a2-3eaa-4c29-b985-ada99a158b88",
   "metadata": {},
   "source": [
    "However, we are not be interested in all available topics. As a matter of fact, for our project, it is only useful to isolate the data about articles related to the environment. Examining the columns, the topic is available in only one of them, so we will extract only that topic in two dataframes that have the same format as [here](#extraction_format) (only difference is that we change the name *views* to *environment_views*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20310772-1f8c-446f-aff9-c92f0c9be4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_environment_df = countries_to_topics_sum_df['STEM.Earth and environment']\n",
    "percent_environment_df = countries_to_topics_percent_df['STEM.Earth and environment']\n",
    "country_to_env_data_sum = {}\n",
    "country_to_env_data_percent = {}\n",
    "for country in sum_environment_df.index:\n",
    "    country_to_env_data_sum[country] = sum_environment_df[country]\n",
    "    country_to_env_data_percent[country] = percent_environment_df[country]\n",
    "sum_environment_df = pd.DataFrame.from_dict(country_to_env_data_sum, orient = 'index').T\n",
    "percent_environment_df = pd.DataFrame.from_dict(country_to_env_data_percent, orient = 'index').T\n",
    "percent_environment_df.index = pd.to_datetime(percent_environment_df.index)\n",
    "\n",
    "new_sum_environment_df = pd.DataFrame()\n",
    "for language in languages_unique:\n",
    "    country_env_sum_data = pd.DataFrame()\n",
    "    \n",
    "    country_env_sum_data['environment_views'] = sum_environment_df[language] + sum_environment_df[language + '.m']\n",
    "    country_env_sum_data['language'] = language\n",
    "    new_sum_environment_df = pd.concat([new_sum_environment_df, country_env_sum_data], axis = 0)\n",
    "sum_environment_df = new_sum_environment_df\n",
    "sum_environment_df.index = pd.to_datetime(sum_environment_df.index)\n",
    "sum_environment_df['date'] = sum_environment_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3724c2fc-506d-4c1d-87c9-6ce8a439257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>environment_views</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>110497</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>142849</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>162644</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>171022</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>183210</td>\n",
       "      <td>ja</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-27</th>\n",
       "      <td>16384</td>\n",
       "      <td>fi</td>\n",
       "      <td>2020-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-28</th>\n",
       "      <td>17269</td>\n",
       "      <td>fi</td>\n",
       "      <td>2020-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-29</th>\n",
       "      <td>17182</td>\n",
       "      <td>fi</td>\n",
       "      <td>2020-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-30</th>\n",
       "      <td>15963</td>\n",
       "      <td>fi</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-31</th>\n",
       "      <td>14373</td>\n",
       "      <td>fi</td>\n",
       "      <td>2020-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            environment_views language       date\n",
       "2018-01-01             110497       ja 2018-01-01\n",
       "2018-01-02             142849       ja 2018-01-02\n",
       "2018-01-03             162644       ja 2018-01-03\n",
       "2018-01-04             171022       ja 2018-01-04\n",
       "2018-01-05             183210       ja 2018-01-05\n",
       "...                       ...      ...        ...\n",
       "2020-07-27              16384       fi 2020-07-27\n",
       "2020-07-28              17269       fi 2020-07-28\n",
       "2020-07-29              17182       fi 2020-07-29\n",
       "2020-07-30              15963       fi 2020-07-30\n",
       "2020-07-31              14373       fi 2020-07-31\n",
       "\n",
       "[13202 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_environment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c7747eb-1689-4bcd-afba-def4a8bb9e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ja.m</th>\n",
       "      <th>it</th>\n",
       "      <th>da.m</th>\n",
       "      <th>tr</th>\n",
       "      <th>no.m</th>\n",
       "      <th>en</th>\n",
       "      <th>sr</th>\n",
       "      <th>tr.m</th>\n",
       "      <th>en.m</th>\n",
       "      <th>no</th>\n",
       "      <th>...</th>\n",
       "      <th>ko.m</th>\n",
       "      <th>fi.m</th>\n",
       "      <th>sr.m</th>\n",
       "      <th>ja</th>\n",
       "      <th>fr</th>\n",
       "      <th>fi</th>\n",
       "      <th>ca</th>\n",
       "      <th>it.m</th>\n",
       "      <th>sv.m</th>\n",
       "      <th>ko</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.002914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.002810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.011972</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.003090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ja.m        it      da.m        tr      no.m        en  \\\n",
       "2018-01-01  0.001414  0.002589  0.001947  0.003699  0.003708  0.003689   \n",
       "2018-01-02  0.002001  0.003256  0.003672  0.003400  0.004326  0.003676   \n",
       "2018-01-03  0.002074  0.003413  0.004139  0.003760  0.004906  0.003920   \n",
       "2018-01-04  0.002029  0.003580  0.004273  0.003828  0.005288  0.004073   \n",
       "2018-01-05  0.002136  0.003422  0.003925  0.003457  0.004078  0.003883   \n",
       "\n",
       "                  sr      tr.m      en.m        no  ...      ko.m      fi.m  \\\n",
       "2018-01-01  0.002651  0.002373  0.002359  0.005613  ...  0.001663  0.003341   \n",
       "2018-01-02  0.003157  0.002486  0.002764  0.007101  ...  0.002024  0.004122   \n",
       "2018-01-03  0.003244  0.003047  0.003071  0.008214  ...  0.001953  0.004057   \n",
       "2018-01-04  0.003960  0.003057  0.003305  0.008870  ...  0.002090  0.004323   \n",
       "2018-01-05  0.003787  0.002363  0.002930  0.008315  ...  0.002155  0.003987   \n",
       "\n",
       "                sr.m        ja        fr        fi        ca      it.m  \\\n",
       "2018-01-01  0.001607  0.002296  0.003844  0.004212  0.009242  0.001771   \n",
       "2018-01-02  0.002492  0.002560  0.004250  0.005175  0.011023  0.002220   \n",
       "2018-01-03  0.002561  0.002667  0.004465  0.005038  0.011034  0.002311   \n",
       "2018-01-04  0.004285  0.003049  0.004455  0.005400  0.011972  0.002481   \n",
       "2018-01-05  0.003053  0.003345  0.004351  0.005054  0.010285  0.002330   \n",
       "\n",
       "                sv.m        ko  \n",
       "2018-01-01  0.003260  0.002914  \n",
       "2018-01-02  0.003829  0.002810  \n",
       "2018-01-03  0.004315  0.003077  \n",
       "2018-01-04  0.004363  0.003090  \n",
       "2018-01-05  0.003549  0.003026  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not really useful piece of data\n",
    "percent_environment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc65be-ee4e-4f2d-a574-30fadda1c6b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### First analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dbb18b1-448a-48f1-86c9-04b805b70f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_path = './Figures/'\n",
    "timeseries_path = 'timeseries/'\n",
    "hists_path = 'hists/'\n",
    "total_views_path = 'all_views/'\n",
    "covid_views_path = 'covid_views/'\n",
    "topic_views_path = 'topic_views/'\n",
    "def make_sub_dirs(main_dir):\n",
    "    os.mkdir(main_dir + total_views_path)\n",
    "    os.mkdir(main_dir + covid_views_path)\n",
    "    os.mkdir(main_dir + topic_views_path)\n",
    "    os.mkdir(main_dir + topic_views_path + total_views_path)\n",
    "    os.mkdir(main_dir + topic_views_path + covid_views_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b9ba0d6-7f74-4f98-b210-178e1385f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figures_path):\n",
    "    os.mkdir(figures_path)\n",
    "    os.mkdir(figures_path + timeseries_path)\n",
    "    os.mkdir(figures_path + hists_path)\n",
    "    make_sub_dirs(figures_path + timeseries_path)\n",
    "    make_sub_dirs(figures_path + hists_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cc92d4b-d14c-4031-a175-7ba9994242c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot_language_views_timeseries(data, country, covid_views = False):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "    filtered_data = data[data['language'] == country]\n",
    "    x = filtered_data.index\n",
    "    y = filtered_data.views\n",
    "    g = sns.lineplot( x = x, y = y)\n",
    "    plt.xticks(fontsize=8)\n",
    "    g.set(xlabel='Dates')\n",
    "    if covid_views:\n",
    "        title = 'Wikipedia page views for articles related to Covid-19 for {}'.format(country)\n",
    "    else:\n",
    "        title = 'Wikipedia page views for {}'.format(country)\n",
    "    g.set(ylabel='Page views', title = title)\n",
    "    #ax.set(xscale=\"log\")\n",
    "    if covid_views:\n",
    "        plt.savefig(figures_path + timeseries_path + covid_views_path + title + \".jpg\")\n",
    "    else:\n",
    "        plt.savefig(figures_path + timeseries_path + total_views_path + title + \".jpg\")\n",
    "    plt.close(fig)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eab251f-d323-4fe6-813a-5f755a2d7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_language_views(data, country, covid_views = False):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "    filtered_data = data[data['language'] == country]\n",
    "    g = sns.histplot(data = filtered_data, x = 'views', bins = 50)\n",
    "    if covid_views:\n",
    "        title = 'Wikipedia views distribution for articles related to Covid-19 {}'.format(country)\n",
    "    else:\n",
    "        title = 'Wikipedia views distribution for {}'.format(country)\n",
    "        \n",
    "    if covid_views:\n",
    "        plt.savefig(figures_path + hists_path + covid_views_path + title + \".jpg\")\n",
    "    else:\n",
    "        plt.savefig(figures_path + hists_path + total_views_path + title + \".jpg\")\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dd5b516-4a7a-4d6a-bdf0-908bf5cfcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country_code in sum_data_df.language.unique():\n",
    "    lineplot_language_views_timeseries(sum_data_df, country_code)\n",
    "    hist_language_views(sum_data_df, country_code)\n",
    "    lineplot_language_views_timeseries(covid_sum_data_df, country_code, True)\n",
    "    hist_language_views(covid_sum_data_df, country_code, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebb1c67e-79bb-4d15-b07b-e2746c3891a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot_topic_views_timeseries(topic_data, country, covid_views = False, topic = 'environment'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "    filtered_data = topic_data[topic_data['language'] == country]\n",
    "    x = filtered_data.index\n",
    "    y = filtered_data.environment_views\n",
    "    g = sns.lineplot( x = x, y = y)\n",
    "    plt.xticks(fontsize=8)\n",
    "    g.set(xlabel='Dates')\n",
    "    if covid_views:\n",
    "        title = 'Wikipedia page views for articles related to Covid-19 for {0} for the {1} topic'.format(country, topic)\n",
    "    else:\n",
    "        title = 'Wikipedia page views for {0} for the {1} topic'.format(country,topic)\n",
    "    g.set(ylabel='Page views', title = title)\n",
    "    if covid_views:\n",
    "        plt.savefig(figures_path + timeseries_path + topic_views_path + covid_views_path + title + \".jpg\")\n",
    "    else:\n",
    "        plt.savefig(figures_path + timeseries_path + topic_views_path + total_views_path + title + \".jpg\")\n",
    "        \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fb73819-8d10-4734-a500-b6798bc4e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_topic_views(topic_data, country, covid_views = False, topic = 'environment'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "    filtered_data = topic_data[topic_data['language'] == country]\n",
    "    g = sns.histplot(data = topic_data, x = 'environment_views', bins = 50)\n",
    "    if covid_views:\n",
    "        title = 'Wikipedia views distribution for articles related to Covid-19 for {0} for the {1} topic'.format(country, topic)\n",
    "    else:\n",
    "        title = 'Wikipedia views distribution for {0} for the {1} topic'.format(country, topic)\n",
    "        \n",
    "    if covid_views:\n",
    "        plt.savefig(figures_path + hists_path + topic_views_path + covid_views_path + title + \".jpg\")\n",
    "    else:\n",
    "        plt.savefig(figures_path + hists_path + topic_views_path + total_views_path + title + \".jpg\")\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a59b533d-115f-4d20-970d-e276b091ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country_code in sum_environment_df.language.unique():\n",
    "    lineplot_topic_views_timeseries(sum_environment_df, country_code)\n",
    "    hist_topic_views(sum_environment_df, country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df811ce-c653-4518-80fd-95b964423b38",
   "metadata": {},
   "source": [
    "**TODO: SOME HYPOTHESIS TESTING AND STUFF WITH THE ENVIRONMENT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e80024c8-db02-4991-87b2-56ea93e6629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for ja: 8.674434578237681e-12\n",
      "Ttest statistic value for ja: -7.231241414327632\n",
      "------------------\n",
      "p-value for it: 0.002239652239545297\n",
      "Ttest statistic value for it: -3.094339981709228\n",
      "------------------\n",
      "p-value for da: 8.548804022807578e-09\n",
      "Ttest statistic value for da: 5.998519188316964\n",
      "------------------\n",
      "p-value for tr: 1.314393887625464e-36\n",
      "Ttest statistic value for tr: -15.476728178676694\n",
      "------------------\n",
      "p-value for no: 0.0003371702009370404\n",
      "Ttest statistic value for no: 3.644641980122951\n",
      "------------------\n",
      "p-value for en: 5.111120077771199e-05\n",
      "Ttest statistic value for en: 4.135571195327151\n",
      "------------------\n",
      "p-value for sr: 2.5049354455646286e-18\n",
      "Ttest statistic value for sr: -9.596560924740071\n",
      "------------------\n",
      "p-value for sv: 3.0797434434976986e-10\n",
      "Ttest statistic value for sv: 6.610574204066698\n",
      "------------------\n",
      "p-value for nl: 0.4461336381813529\n",
      "Don't reject null when alpha = 0.05\n",
      "Don't reject null when using the banferoni correction\n",
      "Ttest statistic value for nl: 0.76330579634987\n",
      "------------------\n",
      "p-value for de: 0.00011587628783902456\n",
      "Ttest statistic value for de: 3.92834732773271\n",
      "------------------\n",
      "p-value for fr: 0.014783701233451938\n",
      "Don't reject null when using the banferoni correction\n",
      "Ttest statistic value for fr: -2.4578423780039396\n",
      "------------------\n",
      "p-value for ca: 0.002299839061135381\n",
      "Ttest statistic value for ca: -3.0861030840362993\n",
      "------------------\n",
      "p-value for ko: 0.06664894050960339\n",
      "Don't reject null when alpha = 0.05\n",
      "Don't reject null when using the banferoni correction\n",
      "Ttest statistic value for ko: -1.8435652850735849\n",
      "------------------\n",
      "p-value for fi: 0.0012515300455661531\n",
      "Ttest statistic value for fi: -3.2710449466689235\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "before_covid_env_topic_views = sum_environment_df[(sum_environment_df.date < '2020-01-01') & \\\n",
    "                                                  (sum_environment_df.date >= '2019-01-01')]\n",
    "during_covid_env_topic_views = sum_environment_df[sum_environment_df.date >= '2020-01-01']\n",
    "more_before_covid = 0\n",
    "more_during_covid = 0\n",
    "for language in sum_environment_df.language.unique():\n",
    "    language_before = before_covid_env_topic_views[before_covid_env_topic_views.language == language]\n",
    "    language_during = during_covid_env_topic_views[during_covid_env_topic_views.language == language]\n",
    "    \n",
    "    language_before.date = language_before.date.apply(lambda date: str(date.month) + '-' + str(date.day))\n",
    "    language_during.date = language_during.date.apply(lambda date: str(date.month) + '-' + str(date.day))\n",
    "    matching = pd.merge(language_before, language_during, on = ['date', 'language'], suffixes = ['_before', '_during'])\n",
    "    stat, pvalue = stats.ttest_rel(matching['environment_views_before'], matching['environment_views_during'])\n",
    "    print(\"p-value for {0}: {1}\".format(language, pvalue))\n",
    "    if(pvalue >= 0.05):\n",
    "        print(\"Don't reject null when alpha = 0.05\")\n",
    "    if(pvalue >= (0.05/14)):\n",
    "        print(\"Don't reject null when using the banferoni correction\")\n",
    "    print(\"Ttest statistic value for {0}: {1}\".format(language, stat))\n",
    "    if(stat < 0):\n",
    "        more_during_covid += 1\n",
    "    else:\n",
    "        more_before_covid += 1\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3b784-6e3e-4890-97f9-6ae2fa3dee62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mobility data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cde0a9-7dbe-43e8-a4a2-8d8437566645",
   "metadata": {},
   "source": [
    "The second type of data we have are mobility data that come from two different sources. The first one is from Apple, who stopped giving out the data in April 2022, and the second one is from Google, which is still available, and more up-to-date (17th of October)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8756df-451c-407d-9e78-7de60a6a921f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apple mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ca5d0e9-b298-450d-8b1a-2b11ead28f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_type</th>\n",
       "      <th>region</th>\n",
       "      <th>transportation_type</th>\n",
       "      <th>2020-01-13</th>\n",
       "      <th>2020-01-14</th>\n",
       "      <th>2020-01-15</th>\n",
       "      <th>2020-01-16</th>\n",
       "      <th>2020-01-17</th>\n",
       "      <th>2020-01-18</th>\n",
       "      <th>2020-01-19</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-04-11</th>\n",
       "      <th>2020-04-12</th>\n",
       "      <th>2020-04-13</th>\n",
       "      <th>2020-04-14</th>\n",
       "      <th>2020-04-15</th>\n",
       "      <th>2020-04-16</th>\n",
       "      <th>2020-04-17</th>\n",
       "      <th>2020-04-18</th>\n",
       "      <th>2020-04-19</th>\n",
       "      <th>2020-04-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country/region</td>\n",
       "      <td>Albania</td>\n",
       "      <td>driving</td>\n",
       "      <td>100</td>\n",
       "      <td>95.30</td>\n",
       "      <td>101.43</td>\n",
       "      <td>97.20</td>\n",
       "      <td>103.55</td>\n",
       "      <td>112.67</td>\n",
       "      <td>104.83</td>\n",
       "      <td>...</td>\n",
       "      <td>25.47</td>\n",
       "      <td>24.89</td>\n",
       "      <td>32.64</td>\n",
       "      <td>31.43</td>\n",
       "      <td>30.67</td>\n",
       "      <td>30.00</td>\n",
       "      <td>29.26</td>\n",
       "      <td>22.94</td>\n",
       "      <td>24.55</td>\n",
       "      <td>31.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country/region</td>\n",
       "      <td>Albania</td>\n",
       "      <td>walking</td>\n",
       "      <td>100</td>\n",
       "      <td>100.68</td>\n",
       "      <td>98.93</td>\n",
       "      <td>98.46</td>\n",
       "      <td>100.85</td>\n",
       "      <td>100.13</td>\n",
       "      <td>82.13</td>\n",
       "      <td>...</td>\n",
       "      <td>27.63</td>\n",
       "      <td>29.59</td>\n",
       "      <td>35.52</td>\n",
       "      <td>38.08</td>\n",
       "      <td>35.48</td>\n",
       "      <td>39.15</td>\n",
       "      <td>34.58</td>\n",
       "      <td>27.76</td>\n",
       "      <td>27.93</td>\n",
       "      <td>36.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country/region</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>driving</td>\n",
       "      <td>100</td>\n",
       "      <td>97.07</td>\n",
       "      <td>102.45</td>\n",
       "      <td>111.21</td>\n",
       "      <td>118.45</td>\n",
       "      <td>124.01</td>\n",
       "      <td>95.44</td>\n",
       "      <td>...</td>\n",
       "      <td>19.40</td>\n",
       "      <td>12.89</td>\n",
       "      <td>21.10</td>\n",
       "      <td>22.29</td>\n",
       "      <td>23.55</td>\n",
       "      <td>24.40</td>\n",
       "      <td>27.17</td>\n",
       "      <td>23.19</td>\n",
       "      <td>14.54</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country/region</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>walking</td>\n",
       "      <td>100</td>\n",
       "      <td>95.11</td>\n",
       "      <td>101.37</td>\n",
       "      <td>112.67</td>\n",
       "      <td>116.72</td>\n",
       "      <td>114.14</td>\n",
       "      <td>84.54</td>\n",
       "      <td>...</td>\n",
       "      <td>15.75</td>\n",
       "      <td>10.45</td>\n",
       "      <td>16.35</td>\n",
       "      <td>16.66</td>\n",
       "      <td>17.42</td>\n",
       "      <td>18.18</td>\n",
       "      <td>18.80</td>\n",
       "      <td>17.03</td>\n",
       "      <td>10.59</td>\n",
       "      <td>18.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country/region</td>\n",
       "      <td>Australia</td>\n",
       "      <td>driving</td>\n",
       "      <td>100</td>\n",
       "      <td>102.98</td>\n",
       "      <td>104.21</td>\n",
       "      <td>108.63</td>\n",
       "      <td>109.08</td>\n",
       "      <td>89.00</td>\n",
       "      <td>99.35</td>\n",
       "      <td>...</td>\n",
       "      <td>26.95</td>\n",
       "      <td>31.72</td>\n",
       "      <td>53.14</td>\n",
       "      <td>55.91</td>\n",
       "      <td>56.56</td>\n",
       "      <td>58.77</td>\n",
       "      <td>47.51</td>\n",
       "      <td>36.90</td>\n",
       "      <td>53.34</td>\n",
       "      <td>56.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geo_type     region transportation_type  2020-01-13  2020-01-14  \\\n",
       "0  country/region    Albania             driving         100       95.30   \n",
       "1  country/region    Albania             walking         100      100.68   \n",
       "2  country/region  Argentina             driving         100       97.07   \n",
       "3  country/region  Argentina             walking         100       95.11   \n",
       "4  country/region  Australia             driving         100      102.98   \n",
       "\n",
       "   2020-01-15  2020-01-16  2020-01-17  2020-01-18  2020-01-19  ...  \\\n",
       "0      101.43       97.20      103.55      112.67      104.83  ...   \n",
       "1       98.93       98.46      100.85      100.13       82.13  ...   \n",
       "2      102.45      111.21      118.45      124.01       95.44  ...   \n",
       "3      101.37      112.67      116.72      114.14       84.54  ...   \n",
       "4      104.21      108.63      109.08       89.00       99.35  ...   \n",
       "\n",
       "   2020-04-11  2020-04-12  2020-04-13  2020-04-14  2020-04-15  2020-04-16  \\\n",
       "0       25.47       24.89       32.64       31.43       30.67       30.00   \n",
       "1       27.63       29.59       35.52       38.08       35.48       39.15   \n",
       "2       19.40       12.89       21.10       22.29       23.55       24.40   \n",
       "3       15.75       10.45       16.35       16.66       17.42       18.18   \n",
       "4       26.95       31.72       53.14       55.91       56.56       58.77   \n",
       "\n",
       "   2020-04-17  2020-04-18  2020-04-19  2020-04-20  \n",
       "0       29.26       22.94       24.55       31.51  \n",
       "1       34.58       27.76       27.93       36.72  \n",
       "2       27.17       23.19       14.54       26.67  \n",
       "3       18.80       17.03       10.59       18.44  \n",
       "4       47.51       36.90       53.34       56.93  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_mobility = pd.read_csv(\"applemobilitytrends-2020-04-20.csv.gz\")\n",
    "apple_mobility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a9fa06d-db95-4cc9-af1f-4bdbceee14d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['driving' 'walking' 'transit']\n",
      "['country/region' 'city']\n"
     ]
    }
   ],
   "source": [
    "print(apple_mobility.transportation_type.unique()) # Three types of transportation\n",
    "print(apple_mobility.geo_type.unique()) # Granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43880ca-f328-48d3-8d29-7a6032ac37e1",
   "metadata": {},
   "source": [
    "The mobility data from Apple we have begins in mid-January 2020, and ends that same year in April. This isn't a big time window, and it doesn't appear that there is earlier data as it has been collected specifically for Covid-19 mobility tracking. We could however try to look for newer information (post-April 2020) on the web.\n",
    "\n",
    "Three types of transportation have been tracked here: driving, walking, and transit. We also have two different granularities about the collected data: either country/world region level, or city level, which are often country capitals.\n",
    "\n",
    "Per day and region, we have the pourcentage of the usage of every transportation mode according to some pre-pandemic baseline computed in early 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "950454d2-86ff-48dd-b1ff-8ff0b03db73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_mobility.isnull().any().any() # There doesn't appear to be missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d70be52-4834-4db0-94af-fd82f13d00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dates strings to date times\n",
    "time_columns = pd.to_datetime(apple_mobility.columns[3:])\n",
    "apple_mobility.columns = apple_mobility.columns[:3].append(time_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c073d86-ab19-4ac4-badd-1964fd8f6ef2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Global mobility from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6bd92cd-d97c-4b8e-9ab7-452405c5e590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "global_mobility_report = pd.read_csv(\"Global_Mobility_Report.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fb5f92b-205c-4d28-a9bf-428ee3fdff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-15 2020-08-25\n"
     ]
    }
   ],
   "source": [
    "print(min(global_mobility_report.date.unique()), max(global_mobility_report.date.unique()))\n",
    "global_mobility_report.date = pd.to_datetime(global_mobility_report.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edad972-d127-446b-af8a-67c16a8896e4",
   "metadata": {},
   "source": [
    "The mobility data from Google we have begins in mid-February 2020, and ends that same year in August. This is more than the given Apple data, despite the fact that both collections happened in the context of Covid-19. The full data can be found in the *Outside data* folder.\n",
    "\n",
    "There are more levels of granularity with this data: for example, for the United Arab Emirates, we might simply talk about the whole country, or it could be specified in the column *sub_region_1* that the row is actually focused on the city of Abu Dhabi. This granularity can be made finer with *sub_region_2*.\n",
    "\n",
    "Per day and region, we have the **difference** in pourcentage usage of various location types (workplaces, etc) according to some pre-pandemic baseline computed in the early weeks of 2020. The baseline was computed *per day* , as people can have different behaviors depending on whether it's the weekend or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80dd5738-cf3a-4043-b2a9-acadecdbf703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_region_code                                   0.000709\n",
       "country_region                                        0.000000\n",
       "sub_region_1                                          0.018154\n",
       "sub_region_2                                          0.180897\n",
       "metro_area                                            0.994122\n",
       "iso_3166_2_code                                       0.813653\n",
       "census_fips_code                                      0.762436\n",
       "date                                                  0.000000\n",
       "retail_and_recreation_percent_change_from_baseline    0.363799\n",
       "grocery_and_pharmacy_percent_change_from_baseline     0.373900\n",
       "parks_percent_change_from_baseline                    0.536971\n",
       "transit_stations_percent_change_from_baseline         0.502960\n",
       "workplaces_percent_change_from_baseline               0.050385\n",
       "residential_percent_change_from_baseline              0.499080\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_mobility_report.isnull().sum()/global_mobility_report.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0842384-66de-4c20-9946-827338430f93",
   "metadata": {},
   "source": [
    "As expected, we have more coarse grained data (no missing data) than finer grained (many sub_region_1 fields are null, and even more sub_region_2 as well). The metropolitan area is very rarely defined, as almost 99.4% of the field is empty values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b6801-62d6-4e94-9436-58cb6361f163",
   "metadata": {},
   "source": [
    "Looking at the differences from baseline, we remark scarcity as well; apart from workplace locations which has a missing rate of only around 5.04%, others go from 36.4% (for retail) to 53.7% (for parks).\n",
    "\n",
    "We can look in more details at the entries which have the missing values for the differences from baseline; first, let's check the intersection of these missing values, to see for example if the absence of one field implies the absence of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d838936d-a2ac-468b-ab42-887ff4764b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_missing = (global_mobility_report.retail_and_recreation_percent_change_from_baseline.isnull())\n",
    "grocery_pharmecy_missing = (global_mobility_report.grocery_and_pharmacy_percent_change_from_baseline.isnull())\n",
    "park_missing = (global_mobility_report.parks_percent_change_from_baseline.isnull())\n",
    "transit_stations_missing = (global_mobility_report.transit_stations_percent_change_from_baseline.isnull())\n",
    "workplace_missing = (global_mobility_report.workplaces_percent_change_from_baseline.isnull())\n",
    "residential_missing = (global_mobility_report.residential_percent_change_from_baseline.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "978f1790-b18d-4cd8-8d1f-44a0007bfecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dict = {}\n",
    "missing_dict['retail'] = retail_missing\n",
    "missing_dict['grocery'] = grocery_pharmecy_missing\n",
    "missing_dict['park'] = park_missing\n",
    "missing_dict['transit_stations'] = transit_stations_missing\n",
    "missing_dict['workplace'] = workplace_missing\n",
    "missing_dict['residential'] = residential_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fec5336-8963-4356-9e17-819108d31272",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_missing = retail_missing & grocery_pharmecy_missing & park_missing & transit_stations_missing & workplace_missing & residential_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdc4607f-70de-4946-9a05-bde04492da30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_missing.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5760f-9377-4cf7-8e31-0605e0cffd19",
   "metadata": {},
   "source": [
    "From the above result, we can conclude that there doesn't appear to be a feature such that if that one is missing, then all the others are missing; this also means that for each entry, there's always at least one feature available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48be2a6-3e08-49f3-a38a-4bcaf74571c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### First analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aafd44-9e64-4335-bdbd-4068d348fadd",
   "metadata": {},
   "source": [
    "Let's now see, for each feature, which countries miss this data; maybe there is a strict subset of countries which have some missing. This will point to the quality/availability of the data for these regions of the world. We will begin with the countries missing some data from retail locations as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4023499c-c942-4271-b393-b98db788feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of countries considered in the collected data: 135\n"
     ]
    }
   ],
   "source": [
    "# Total number of countries considered\n",
    "print(\"Total number of countries considered in the collected data: {}\"\\\n",
    "      .format(global_mobility_report.country_region.unique().size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd26383b-6fa7-48c8-8f6b-04b805ed95f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_missing = {}\n",
    "intersection = set()\n",
    "for location in missing_dict:\n",
    "    countries_missing[location] = global_mobility_report[missing_dict[location]].country_region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d2688e9-96fa-4074-ac39-ce8931753177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Length of the current intersection: 81\n",
      "Length of the current union: 81\n",
      "--------------------------------------------\n",
      "Length of the current intersection: 80\n",
      "Length of the current union: 86\n",
      "--------------------------------------------\n",
      "Length of the current intersection: 77\n",
      "Length of the current union: 90\n",
      "--------------------------------------------\n",
      "Length of the current intersection: 77\n",
      "Length of the current union: 93\n",
      "--------------------------------------------\n",
      "Length of the current intersection: 56\n",
      "Length of the current union: 93\n",
      "--------------------------------------------\n",
      "Length of the current intersection: 56\n",
      "Length of the current union: 98\n"
     ]
    }
   ],
   "source": [
    "intersection_of_countries = set(countries_missing['retail'])\n",
    "union_of_countries = set(countries_missing['retail'])\n",
    "for location in countries_missing:\n",
    "    print(\"--------------------------------------------\")\n",
    "    intersection_of_countries = intersection_of_countries.intersection(set(countries_missing[location]))\n",
    "    union_of_countries = union_of_countries.union(set(countries_missing[location]))\n",
    "    print(\"Length of the current intersection: {}\".format(len(intersection_of_countries)))\n",
    "    print(\"Length of the current union: {}\".format(len(union_of_countries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd14d394-a871-42f1-be26-cfd19bd39b3e",
   "metadata": {},
   "source": [
    "As we can see, out of the total number of 135 , if a country misses some data then it's in a strict subset of the same 98 countries. For 56 of those, at least one data miss per feature is recorded. This of course doesn't mean that data is always missing for these countries; we simply know that if we record one data miss, we know that it's in one of these 98. It might also be interesting to know which countries *never* have missing data.\n",
    "\n",
    "We will now map the 98 (maybe 56?) countries to their continents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30089250-422e-452e-aa6a-fad2380199ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries_code = global_mobility_report[global_mobility_report['country_region'].isin(union_of_countries)].country_region_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5ac1f15-561e-43fd-ad57-f2a88f93b719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AS', 'NA', 'AF', 'SA', 'EU', 'OC'])\n"
     ]
    }
   ],
   "source": [
    "continent_to_country_missing = {}\n",
    "for code in missing_countries_code:\n",
    "    if type(code) is float:\n",
    "        continue\n",
    "    continent = pc.country_alpha2_to_continent_code(code)\n",
    "    if continent not in continent_to_country_missing:\n",
    "        continent_to_country_missing[continent] = []\n",
    "    continent_to_country_missing[continent].append(code)\n",
    "print(continent_to_country_missing.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f399a2a-611f-4075-991f-7045dce5de94",
   "metadata": {},
   "source": [
    "Which continent each code corresponds to can be found on https://datahub.io/core/continent-codes . Let's now see the countries from which data is never missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "352b78e7-baeb-4815-8883-7144aa27110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_missing_countries_code = global_mobility_report[~(global_mobility_report['country_region'].isin(union_of_countries))].country_region_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f06f6aa6-ffeb-4c77-8059-3a671ac79e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AS', 'EU', 'NA', 'OC', 'AF', 'SA'])\n"
     ]
    }
   ],
   "source": [
    "continent_to_country_not_missing = {}\n",
    "for code in not_missing_countries_code:\n",
    "    if type(code) is float:\n",
    "        continue\n",
    "    continent = pc.country_alpha2_to_continent_code(code)\n",
    "    if continent not in continent_to_country_not_missing:\n",
    "        continent_to_country_not_missing[continent] = []\n",
    "    continent_to_country_not_missing[continent].append(code)\n",
    "print(continent_to_country_not_missing.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad3b17-2a28-43bc-81c5-b1eaa70ec442",
   "metadata": {},
   "source": [
    "It appears that data can be missing from any part of the world, and so no conclusions can be made immediatly about a country based on which continent it's on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3520c-e6f1-4aad-9d20-e26f11905234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd197c-727e-4947-a143-6f56e876266d",
   "metadata": {},
   "source": [
    "In this data, each language is mapped to the main country of usage except for English, where the language's usage is very high in multiple countries such that it couldn't be mapped to a single country. As such, for that language, we have most of the data missing.\n",
    "\n",
    "Per country, the pandemic timeline is represented, such as the first registered case, the first death, etc.\n",
    "\n",
    "Note that the paper says that nine languages are spoken in a single language, but we have more than that here (reason for that unknown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9973ea25-9f2c-48af-b150-05a941d8988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>1st case</th>\n",
       "      <th>1st death</th>\n",
       "      <th>School closure</th>\n",
       "      <th>Public events banned</th>\n",
       "      <th>Lockdown</th>\n",
       "      <th>Mobility</th>\n",
       "      <th>Normalcy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>2020-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2020-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>2020-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2020-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nl</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>2020-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2020-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sr</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>2020-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sv</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2020-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ko</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2020-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ca</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fi</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ja</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>en</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang   1st case  1st death School closure Public events banned   Lockdown  \\\n",
       "0    fr 2020-01-24 2020-02-14     2020-03-14           2020-03-13 2020-03-17   \n",
       "1    da 2020-02-27 2020-03-12     2020-03-13           2020-03-12 2020-03-18   \n",
       "2    de 2020-01-27 2020-03-09     2020-03-14           2020-03-22 2020-03-22   \n",
       "3    it 2020-01-31 2020-02-22     2020-03-05           2020-03-09 2020-03-11   \n",
       "4    nl 2020-02-27 2020-03-06     2020-03-11           2020-03-24        NaT   \n",
       "5    no 2020-02-26 2020-02-26     2020-03-13           2020-03-12 2020-03-24   \n",
       "6    sr 2020-03-06 2020-03-20     2020-03-15           2020-03-21 2020-03-21   \n",
       "7    sv 2020-01-31 2020-03-11     2020-03-18           2020-03-12        NaT   \n",
       "8    ko 2020-01-20 2020-02-20     2020-02-23                  NaT        NaT   \n",
       "9    ca 2020-01-31 2020-02-13     2020-03-12           2020-03-08 2020-03-14   \n",
       "10   fi 2020-01-29 2020-03-21     2020-03-16           2020-03-16        NaT   \n",
       "11   ja 2020-01-16 2020-02-13     2020-02-27           2020-02-25        NaT   \n",
       "12   en        NaT        NaT            NaT                  NaT        NaT   \n",
       "\n",
       "     Mobility   Normalcy  \n",
       "0  2020-03-16 2020-07-02  \n",
       "1  2020-03-11 2020-06-05  \n",
       "2  2020-03-16 2020-07-10  \n",
       "3  2020-03-11 2020-06-26  \n",
       "4  2020-03-16 2020-05-29  \n",
       "5  2020-03-11 2020-06-04  \n",
       "6  2020-03-16 2020-05-02  \n",
       "7  2020-03-11 2020-06-05  \n",
       "8  2020-02-25 2020-04-15  \n",
       "9  2020-03-16        NaT  \n",
       "10 2020-03-16 2020-05-21  \n",
       "11 2020-03-31 2020-06-14  \n",
       "12 2020-03-16 2020-05-21  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interventions = pd.read_csv(\"interventions.csv\")\n",
    "def transform_column(column_name):\n",
    "    interventions[column_name] = pd.to_datetime(interventions[column_name])\n",
    "for intervention in interventions.columns[1:]:\n",
    "    transform_column(intervention)\n",
    "interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b010d-f886-478f-8bc1-822d7e9c7030",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a8b32-8c3c-4471-a778-6bcb6d7aad27",
   "metadata": {},
   "source": [
    "Simply maps each considered article to the topics it is related to. A single article can be mapped to multiple topics. The number of articles per topic can be found in the [timeseries](#timeseries) data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b192856b-95ed-471c-89ce-6fe5e3d0a789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#topics_linked = pd.read_csv(\"topics_linked.csv.xz\")\n",
    "#topics_linked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456c6a7-ab1e-45be-953d-89fd2c18ea56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d54964-aa0b-438c-9c5d-9dae044dfff5",
   "metadata": {},
   "source": [
    "First of all, let us keep from both mobility datasets only the countries that were considered in the original timeseries. We mapped the english language to Washington DC, the catalan language to Barcelona, and the Korean language both to Seoul and South Korea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31fbba95-698d-4a7a-9c1c-b87fcbe77304",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_wiki_code = {'Japan' : 'ja', 'Italy': 'it', 'Denmark': 'da', 'Turkey': 'tr', 'Norway': 'no', 'Serbia': 'sr',\\\n",
    "                       'Sweden': 'sv', 'Netherlands': 'nl', 'Germany': 'de', 'France': 'fr', 'Barcelona': 'ca', \\\n",
    "                        'South Korea': 'ko', 'Finland': 'fi', 'District of Columbia' : 'en', 'Washington DC': 'en', 'Seoul': 'ko'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f2ff321-1a53-4943-adad-abb95a3b4dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Germany', 'Denmark', 'Spain', 'Finland', 'France', 'Italy',\n",
       "       'Japan', 'South Korea', 'Netherlands', 'Norway', 'Serbia',\n",
       "       'Sweden', 'Turkey', 'United States'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_countries_to_fine_grained(x):\n",
    "    if x == 'Spain':\n",
    "        return 'ca'\n",
    "    if x == 'United States':\n",
    "        return 'en'\n",
    "    if x == 'Seoul':\n",
    "        return ko\n",
    "    return country_to_wiki_code[x]\n",
    "\n",
    "filtered_global_mobility_report = global_mobility_report[global_mobility_report['country_region'].isin(country_to_wiki_code)|\\\n",
    "                                                        global_mobility_report['sub_region_1'].isin(country_to_wiki_code)|\\\n",
    "                                                        global_mobility_report['sub_region_2'].isin(country_to_wiki_code)].copy()\n",
    "filtered_global_mobility_report.loc[:,'country_region_code'] = filtered_global_mobility_report.country_region.apply(lambda x: map_countries_to_fine_grained(x))\n",
    "filtered_global_mobility_report.index = range(len(filtered_global_mobility_report))\n",
    "filtered_global_mobility_report.country_region.unique() # There is data about all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e55757c-9326-4dd1-90c8-476d0bb80dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Have to keep for each country only the capital/concerned city data\n",
    "cities_global_mobility_report = pd.DataFrame()\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_1'] == 'Tokyo'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_2'] == 'Copenhagen Municipality'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_1'] == 'Berlin'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_1'] == 'Oslo'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_2'] == 'Barcelona'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_2'] == 'Helsinki'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_2'] == 'Paris'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_2'] == 'Metropolitan City of Rome'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['metro_area'] == 'Seoul Metropolitan Area'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_2'] == 'Government of Amsterdam'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['metro_area'] == 'Belgrade Metropolitan Area'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_2'] == 'Stockholm Municipality'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_1'] == 'Ankara'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_2'] == 'Barcelona'] ])\n",
    "cities_global_mobility_report = pd.concat([cities_global_mobility_report, filtered_global_mobility_report[filtered_global_mobility_report['sub_region_1'] == 'District of Columbia'] ])\n",
    "cities_global_mobility_report = cities_global_mobility_report[['country_region_code', 'date', 'retail_and_recreation_percent_change_from_baseline',\\\n",
    "                              'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline',\\\n",
    "                              'transit_stations_percent_change_from_baseline','workplaces_percent_change_from_baseline',\\\n",
    "                              'residential_percent_change_from_baseline']]\n",
    "cities_global_mobility_report = cities_global_mobility_report.rename(columns={'country_region_code': 'language'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e113735-212c-428d-b0bd-6bbd74c92038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Denmark' 'Finland' 'France' 'Germany' 'Italy' 'Japan' 'Netherlands'\n",
      " 'Norway' 'Serbia' 'Sweden' 'Turkey' 'Barcelona' 'Seoul' 'Washington DC']\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_type</th>\n",
       "      <th>region</th>\n",
       "      <th>transportation_type</th>\n",
       "      <th>2020-01-13 00:00:00</th>\n",
       "      <th>2020-01-14 00:00:00</th>\n",
       "      <th>2020-01-15 00:00:00</th>\n",
       "      <th>2020-01-16 00:00:00</th>\n",
       "      <th>2020-01-17 00:00:00</th>\n",
       "      <th>2020-01-18 00:00:00</th>\n",
       "      <th>2020-01-19 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-04-11 00:00:00</th>\n",
       "      <th>2020-04-12 00:00:00</th>\n",
       "      <th>2020-04-13 00:00:00</th>\n",
       "      <th>2020-04-14 00:00:00</th>\n",
       "      <th>2020-04-15 00:00:00</th>\n",
       "      <th>2020-04-16 00:00:00</th>\n",
       "      <th>2020-04-17 00:00:00</th>\n",
       "      <th>2020-04-18 00:00:00</th>\n",
       "      <th>2020-04-19 00:00:00</th>\n",
       "      <th>2020-04-20 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>country/region</td>\n",
       "      <td>da</td>\n",
       "      <td>driving</td>\n",
       "      <td>100</td>\n",
       "      <td>103.67</td>\n",
       "      <td>105.55</td>\n",
       "      <td>104.16</td>\n",
       "      <td>110.40</td>\n",
       "      <td>105.47</td>\n",
       "      <td>103.52</td>\n",
       "      <td>...</td>\n",
       "      <td>71.32</td>\n",
       "      <td>71.54</td>\n",
       "      <td>73.58</td>\n",
       "      <td>77.88</td>\n",
       "      <td>80.32</td>\n",
       "      <td>82.37</td>\n",
       "      <td>85.22</td>\n",
       "      <td>80.85</td>\n",
       "      <td>84.05</td>\n",
       "      <td>85.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>country/region</td>\n",
       "      <td>da</td>\n",
       "      <td>transit</td>\n",
       "      <td>100</td>\n",
       "      <td>98.09</td>\n",
       "      <td>98.22</td>\n",
       "      <td>99.55</td>\n",
       "      <td>111.53</td>\n",
       "      <td>108.82</td>\n",
       "      <td>102.06</td>\n",
       "      <td>...</td>\n",
       "      <td>32.59</td>\n",
       "      <td>34.40</td>\n",
       "      <td>35.26</td>\n",
       "      <td>34.36</td>\n",
       "      <td>37.09</td>\n",
       "      <td>37.28</td>\n",
       "      <td>40.06</td>\n",
       "      <td>38.39</td>\n",
       "      <td>42.40</td>\n",
       "      <td>41.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>country/region</td>\n",
       "      <td>da</td>\n",
       "      <td>walking</td>\n",
       "      <td>100</td>\n",
       "      <td>99.31</td>\n",
       "      <td>104.04</td>\n",
       "      <td>107.99</td>\n",
       "      <td>131.40</td>\n",
       "      <td>126.32</td>\n",
       "      <td>96.40</td>\n",
       "      <td>...</td>\n",
       "      <td>65.98</td>\n",
       "      <td>69.45</td>\n",
       "      <td>60.65</td>\n",
       "      <td>66.49</td>\n",
       "      <td>70.92</td>\n",
       "      <td>74.24</td>\n",
       "      <td>81.08</td>\n",
       "      <td>82.95</td>\n",
       "      <td>79.49</td>\n",
       "      <td>83.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>country/region</td>\n",
       "      <td>fi</td>\n",
       "      <td>driving</td>\n",
       "      <td>100</td>\n",
       "      <td>102.42</td>\n",
       "      <td>105.41</td>\n",
       "      <td>104.46</td>\n",
       "      <td>117.78</td>\n",
       "      <td>120.16</td>\n",
       "      <td>112.58</td>\n",
       "      <td>...</td>\n",
       "      <td>76.06</td>\n",
       "      <td>54.91</td>\n",
       "      <td>74.72</td>\n",
       "      <td>72.53</td>\n",
       "      <td>75.78</td>\n",
       "      <td>76.80</td>\n",
       "      <td>88.83</td>\n",
       "      <td>87.21</td>\n",
       "      <td>86.59</td>\n",
       "      <td>84.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>country/region</td>\n",
       "      <td>fi</td>\n",
       "      <td>transit</td>\n",
       "      <td>100</td>\n",
       "      <td>98.58</td>\n",
       "      <td>99.52</td>\n",
       "      <td>101.67</td>\n",
       "      <td>104.50</td>\n",
       "      <td>101.66</td>\n",
       "      <td>98.45</td>\n",
       "      <td>...</td>\n",
       "      <td>34.02</td>\n",
       "      <td>32.26</td>\n",
       "      <td>41.28</td>\n",
       "      <td>39.78</td>\n",
       "      <td>39.22</td>\n",
       "      <td>36.50</td>\n",
       "      <td>40.39</td>\n",
       "      <td>37.89</td>\n",
       "      <td>42.44</td>\n",
       "      <td>46.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          geo_type region transportation_type  2020-01-13 00:00:00  \\\n",
       "31  country/region     da             driving                  100   \n",
       "32  country/region     da             transit                  100   \n",
       "33  country/region     da             walking                  100   \n",
       "39  country/region     fi             driving                  100   \n",
       "40  country/region     fi             transit                  100   \n",
       "\n",
       "    2020-01-14 00:00:00  2020-01-15 00:00:00  2020-01-16 00:00:00  \\\n",
       "31               103.67               105.55               104.16   \n",
       "32                98.09                98.22                99.55   \n",
       "33                99.31               104.04               107.99   \n",
       "39               102.42               105.41               104.46   \n",
       "40                98.58                99.52               101.67   \n",
       "\n",
       "    2020-01-17 00:00:00  2020-01-18 00:00:00  2020-01-19 00:00:00  ...  \\\n",
       "31               110.40               105.47               103.52  ...   \n",
       "32               111.53               108.82               102.06  ...   \n",
       "33               131.40               126.32                96.40  ...   \n",
       "39               117.78               120.16               112.58  ...   \n",
       "40               104.50               101.66                98.45  ...   \n",
       "\n",
       "    2020-04-11 00:00:00  2020-04-12 00:00:00  2020-04-13 00:00:00  \\\n",
       "31                71.32                71.54                73.58   \n",
       "32                32.59                34.40                35.26   \n",
       "33                65.98                69.45                60.65   \n",
       "39                76.06                54.91                74.72   \n",
       "40                34.02                32.26                41.28   \n",
       "\n",
       "    2020-04-14 00:00:00  2020-04-15 00:00:00  2020-04-16 00:00:00  \\\n",
       "31                77.88                80.32                82.37   \n",
       "32                34.36                37.09                37.28   \n",
       "33                66.49                70.92                74.24   \n",
       "39                72.53                75.78                76.80   \n",
       "40                39.78                39.22                36.50   \n",
       "\n",
       "    2020-04-17 00:00:00  2020-04-18 00:00:00  2020-04-19 00:00:00  \\\n",
       "31                85.22                80.85                84.05   \n",
       "32                40.06                38.39                42.40   \n",
       "33                81.08                82.95                79.49   \n",
       "39                88.83                87.21                86.59   \n",
       "40                40.39                37.89                42.44   \n",
       "\n",
       "    2020-04-20 00:00:00  \n",
       "31                85.69  \n",
       "32                41.87  \n",
       "33                83.64  \n",
       "39                84.52  \n",
       "40                46.86  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_apple_mobility = apple_mobility[apple_mobility['region'].isin(country_to_wiki_code)].copy()\n",
    "print(filtered_apple_mobility.region.unique()) # There is data about all countries, except South Korea\n",
    "print(\"-----\")\n",
    "filtered_apple_mobility.region = filtered_apple_mobility.region.apply(lambda x: country_to_wiki_code[x])\n",
    "filtered_apple_mobility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a6722524-124c-4b1d-a42b-b6f0fedefcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_apple_mobility = pd.DataFrame()\n",
    "for language in sum_data_df.language.unique():\n",
    "    tmp = filtered_apple_mobility[filtered_apple_mobility['region'] == language].T.iloc[2:].copy()\n",
    "    tmp.columns = tmp.iloc[0]\n",
    "    tmp = tmp.iloc[1:]\n",
    "    tmp['language'] = language\n",
    "    tmp['date'] = tmp.index\n",
    "    new_apple_mobility = pd.concat([new_apple_mobility, tmp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e266794a-a6d3-4e08-8ff6-a1b37b0bbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_merge1 = sum_data_df.merge(new_apple_mobility, on = ['language', 'date'])\n",
    "tmp_merge2 = tmp_merge1.merge(sum_environment_df, on = ['language', 'date'])\n",
    "final_merge = tmp_merge2.merge(cities_global_mobility_report, on = ['date', 'language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bc8abb3-9b24-4ad9-b11e-1f5107a2db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge[['driving', 'transit', 'walking']] = final_merge[['driving', 'transit', 'walking']].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "657d07f3-c29b-42f0-a60e-5f653f824a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>driving</th>\n",
       "      <th>transit</th>\n",
       "      <th>walking</th>\n",
       "      <th>environment_views</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32829116</td>\n",
       "      <td>ja</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>131.54</td>\n",
       "      <td>128.41</td>\n",
       "      <td>138.76</td>\n",
       "      <td>152200</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37797411</td>\n",
       "      <td>ja</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>114.42</td>\n",
       "      <td>114.64</td>\n",
       "      <td>119.97</td>\n",
       "      <td>174462</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34293756</td>\n",
       "      <td>ja</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>111.43</td>\n",
       "      <td>112.88</td>\n",
       "      <td>122.20</td>\n",
       "      <td>203263</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32288981</td>\n",
       "      <td>ja</td>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>111.19</td>\n",
       "      <td>112.02</td>\n",
       "      <td>122.62</td>\n",
       "      <td>190820</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31509643</td>\n",
       "      <td>ja</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>112.58</td>\n",
       "      <td>112.54</td>\n",
       "      <td>124.25</td>\n",
       "      <td>192859</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      views language       date  driving  transit  walking  environment_views  \\\n",
       "0  32829116       ja 2020-02-15   131.54   128.41   138.76             152200   \n",
       "1  37797411       ja 2020-02-16   114.42   114.64   119.97             174462   \n",
       "2  34293756       ja 2020-02-17   111.43   112.88   122.20             203263   \n",
       "3  32288981       ja 2020-02-18   111.19   112.02   122.62             190820   \n",
       "4  31509643       ja 2020-02-19   112.58   112.54   124.25             192859   \n",
       "\n",
       "   retail_and_recreation_percent_change_from_baseline  \\\n",
       "0                                               -2.0    \n",
       "1                                              -13.0    \n",
       "2                                               -4.0    \n",
       "3                                               -2.0    \n",
       "4                                               -4.0    \n",
       "\n",
       "   grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "0                                                5.0   \n",
       "1                                               -9.0   \n",
       "2                                                3.0   \n",
       "3                                                3.0   \n",
       "4                                                2.0   \n",
       "\n",
       "   parks_percent_change_from_baseline  \\\n",
       "0                                 9.0   \n",
       "1                               -37.0   \n",
       "2                                -2.0   \n",
       "3                                 3.0   \n",
       "4                                 8.0   \n",
       "\n",
       "   transit_stations_percent_change_from_baseline  \\\n",
       "0                                            1.0   \n",
       "1                                           -9.0   \n",
       "2                                           -1.0   \n",
       "3                                           -3.0   \n",
       "4                                           -5.0   \n",
       "\n",
       "   workplaces_percent_change_from_baseline  \\\n",
       "0                                      4.0   \n",
       "1                                     -1.0   \n",
       "2                                      1.0   \n",
       "3                                      0.0   \n",
       "4                                     -1.0   \n",
       "\n",
       "   residential_percent_change_from_baseline  \n",
       "0                                       1.0  \n",
       "1                                       3.0  \n",
       "2                                       0.0  \n",
       "3                                       1.0  \n",
       "4                                       1.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce0f6901-1d79-4fc6-98a9-a7f269e52a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>driving</th>\n",
       "      <th>transit</th>\n",
       "      <th>walking</th>\n",
       "      <th>environment_views</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.064000e+03</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2.064000e+03</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1764.000000</td>\n",
       "      <td>1677.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1656.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.381267e+07</td>\n",
       "      <td>76.074157</td>\n",
       "      <td>71.410960</td>\n",
       "      <td>70.857510</td>\n",
       "      <td>1.088405e+05</td>\n",
       "      <td>-33.368634</td>\n",
       "      <td>-10.442744</td>\n",
       "      <td>-14.338104</td>\n",
       "      <td>-30.759610</td>\n",
       "      <td>-26.087702</td>\n",
       "      <td>11.700483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.479925e+07</td>\n",
       "      <td>38.627975</td>\n",
       "      <td>58.948022</td>\n",
       "      <td>44.029501</td>\n",
       "      <td>3.366268e+05</td>\n",
       "      <td>34.420121</td>\n",
       "      <td>26.223322</td>\n",
       "      <td>41.581843</td>\n",
       "      <td>33.233041</td>\n",
       "      <td>30.103877</td>\n",
       "      <td>12.448648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.891940e+05</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>8.230000</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>5.024000e+03</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-93.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.331293e+06</td>\n",
       "      <td>45.060000</td>\n",
       "      <td>22.807500</td>\n",
       "      <td>31.787500</td>\n",
       "      <td>2.097175e+04</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>-42.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.826532e+06</td>\n",
       "      <td>72.085000</td>\n",
       "      <td>55.305000</td>\n",
       "      <td>62.420000</td>\n",
       "      <td>2.780000e+04</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.864555e+06</td>\n",
       "      <td>108.920000</td>\n",
       "      <td>108.845000</td>\n",
       "      <td>110.057500</td>\n",
       "      <td>3.452900e+04</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.062923e+08</td>\n",
       "      <td>161.690000</td>\n",
       "      <td>322.180000</td>\n",
       "      <td>194.340000</td>\n",
       "      <td>2.252979e+06</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              views      driving     transit      walking  environment_views  \\\n",
       "count  2.064000e+03  2064.000000  792.000000  2064.000000       2.064000e+03   \n",
       "mean   1.381267e+07    76.074157   71.410960    70.857510       1.088405e+05   \n",
       "std    4.479925e+07    38.627975   58.948022    44.029501       3.366268e+05   \n",
       "min    3.891940e+05     8.700000    8.230000     3.780000       5.024000e+03   \n",
       "25%    2.331293e+06    45.060000   22.807500    31.787500       2.097175e+04   \n",
       "50%    2.826532e+06    72.085000   55.305000    62.420000       2.780000e+04   \n",
       "75%    3.864555e+06   108.920000  108.845000   110.057500       3.452900e+04   \n",
       "max    3.062923e+08   161.690000  322.180000   194.340000       2.252979e+06   \n",
       "\n",
       "       retail_and_recreation_percent_change_from_baseline  \\\n",
       "count                                        1728.000000    \n",
       "mean                                          -33.368634    \n",
       "std                                            34.420121    \n",
       "min                                          -100.000000    \n",
       "25%                                           -61.000000    \n",
       "50%                                           -30.000000    \n",
       "75%                                            -1.000000    \n",
       "max                                            62.000000    \n",
       "\n",
       "       grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "count                                        1764.000000   \n",
       "mean                                          -10.442744   \n",
       "std                                            26.223322   \n",
       "min                                           -98.000000   \n",
       "25%                                           -23.000000   \n",
       "50%                                            -3.000000   \n",
       "75%                                             5.000000   \n",
       "max                                           107.000000   \n",
       "\n",
       "       parks_percent_change_from_baseline  \\\n",
       "count                         1677.000000   \n",
       "mean                           -14.338104   \n",
       "std                             41.581843   \n",
       "min                            -97.000000   \n",
       "25%                            -42.000000   \n",
       "50%                             -8.000000   \n",
       "75%                             12.000000   \n",
       "max                            164.000000   \n",
       "\n",
       "       transit_stations_percent_change_from_baseline  \\\n",
       "count                                    1951.000000   \n",
       "mean                                      -30.759610   \n",
       "std                                        33.233041   \n",
       "min                                       -96.000000   \n",
       "25%                                       -60.000000   \n",
       "50%                                       -24.000000   \n",
       "75%                                        -1.000000   \n",
       "max                                        45.000000   \n",
       "\n",
       "       workplaces_percent_change_from_baseline  \\\n",
       "count                              1984.000000   \n",
       "mean                                -26.087702   \n",
       "std                                  30.103877   \n",
       "min                                 -93.000000   \n",
       "25%                                 -50.000000   \n",
       "50%                                 -25.000000   \n",
       "75%                                   2.000000   \n",
       "max                                  20.000000   \n",
       "\n",
       "       residential_percent_change_from_baseline  \n",
       "count                               1656.000000  \n",
       "mean                                  11.700483  \n",
       "std                                   12.448648  \n",
       "min                                   -5.000000  \n",
       "25%                                    0.000000  \n",
       "50%                                    9.000000  \n",
       "75%                                   22.000000  \n",
       "max                                   47.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bae0209-9dcb-4a6a-99a4-15e5fb2ba0dc",
   "metadata": {},
   "source": [
    "## Regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca22fe3f-46b4-4b18-bc5a-57a2e299298c",
   "metadata": {},
   "source": [
    "We can now try to do some regression analysis, with the number of environment views as output, and using the columns of *final_merge* as covariates, to see if we can fit some hyperplane to this data. First let us normalize the covariates, as well as the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45682be3-ec31-4dd6-8e35-9f67208af0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = ['driving', 'transit', 'walking', 'retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e83005e-2e56-404f-90b0-76a58164bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_columns:\n",
    "    final_merge[column] = (final_merge[column] - final_merge[column].mean())/final_merge[column].std()\n",
    "    \n",
    "final_merge['environment_views'] = (final_merge['environment_views'] - final_merge['environment_views'].mean())/final_merge['environment_views'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830641e7-d9ee-4b5a-b911-775555c8be65",
   "metadata": {},
   "source": [
    "First we will use all covariates as predictors, with no interactions between them. It may be useful to do all of this for each language separately, to see how languages/capitas differ from each other in what affects the environment views more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5fc8e7a3-8181-43af-bdcb-0913b89e5d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:      environment_views   R-squared:                       0.135\n",
      "Model:                            OLS   Adj. R-squared:                  0.125\n",
      "Method:                 Least Squares   F-statistic:                     13.53\n",
      "Date:                Fri, 11 Nov 2022   Prob (F-statistic):           2.64e-20\n",
      "Time:                        11:57:01   Log-Likelihood:                -1402.1\n",
      "No. Observations:                 790   AIC:                             2824.\n",
      "Df Residuals:                     780   BIC:                             2871.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================================================\n",
      "                                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                              0.2151      0.073      2.941      0.003       0.072       0.359\n",
      "driving                                               -0.5888      0.214     -2.757      0.006      -1.008      -0.170\n",
      "transit                                               -0.5747      0.114     -5.029      0.000      -0.799      -0.350\n",
      "walking                                                0.8149      0.205      3.983      0.000       0.413       1.217\n",
      "retail_and_recreation_percent_change_from_baseline     2.0673      0.302      6.852      0.000       1.475       2.660\n",
      "grocery_and_pharmacy_percent_change_from_baseline     -0.0462      0.112     -0.413      0.680      -0.266       0.173\n",
      "parks_percent_change_from_baseline                    -0.6323      0.089     -7.105      0.000      -0.807      -0.458\n",
      "transit_stations_percent_change_from_baseline         -1.2019      0.332     -3.618      0.000      -1.854      -0.550\n",
      "workplaces_percent_change_from_baseline               -0.7181      0.285     -2.516      0.012      -1.278      -0.158\n",
      "residential_percent_change_from_baseline              -0.5816      0.230     -2.530      0.012      -1.033      -0.130\n",
      "==============================================================================\n",
      "Omnibus:                      381.619   Durbin-Watson:                   0.138\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1580.059\n",
      "Skew:                           2.341   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.107   Cond. No.                         24.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula=\"\"\"environment_views ~ driving + transit + walking + retail_and_recreation_percent_change_from_baseline + grocery_and_pharmacy_percent_change_from_baseline\n",
    "                        + parks_percent_change_from_baseline + transit_stations_percent_change_from_baseline  + workplaces_percent_change_from_baseline + residential_percent_change_from_baseline\"\"\", data=final_merge)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c80f31-c622-4e74-9903-65a1bf22a3ab",
   "metadata": {},
   "source": [
    "### Let's try to interpret the fitted model:\n",
    "- the fraction of explained variance is equal to 13.3% when using the full data\n",
    "- it appears that the possibility of either driving or taking public transports (either in the *transit* or the *transit_stations_percent_change_from_baseline* variables) is associated with lower views on environment articles. More walking on the other hand is associated with more views\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0cd27-532c-4ba3-a3f1-2dc31c807f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
